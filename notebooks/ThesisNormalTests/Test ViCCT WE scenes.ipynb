{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import models.ViCCT.ViCCTModels  # Need to register the models!\n",
    "import models.ViCCT.ViCCTModelsFunctional  # Need to register the models!\n",
    "\n",
    "from timm.models import create_model\n",
    "from datasets.dataset_utils import img_equal_unsplit\n",
    "import importlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ViCCT_small'  # Must be something like 'deit_small_distilled_patch16_224'.\n",
    "trained_model_path = 'D:\\\\Bureaublad\\\\save_state_ep_250_new_best_MAE_4.971.pth'  # The path to trained model file (something like XYZ.pth)\n",
    "label_factor = 3000  # The label factor used to train this specific model.\n",
    "dataset = 'WE_ViCCT_Meta'  # Must be the exact name of the dataset\n",
    "save_results = False  # When true, save the images, GTs and predictions. A folder for this is created automatically.\n",
    "set_to_eval = 'test'  # val', 'test'. Which split to test the model on. 'train' does not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = importlib.import_module(f'datasets.meta.{dataset}.loading_data').loading_data\n",
    "cfg_data = importlib.import_module(f'datasets.meta.{dataset}.settings').cfg_data\n",
    "\n",
    "train_loaders, val_loaders, test_loaders, restore_transform = dataloader()\n",
    "if set_to_eval == 'val':\n",
    "    my_dataloaders = val_loaders\n",
    "elif set_to_eval == 'test':\n",
    "    my_dataloaders = test_loaders\n",
    "else:\n",
    "    print(f'Error: invalid set --> {set_to_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "if save_results:\n",
    "    save_folder = 'DeiT_meta' + '_' + dataset + '_' + set_to_eval + '_' + time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "    save_dir = os.path.join('notebooks', save_folder)  # Manually change here is you want to save somewhere else\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "        model_name,\n",
    "        init_path=None,\n",
    "        num_classes=1000,  # Not yet used anyway. Must match pretrained model!\n",
    "        drop_rate=0.,\n",
    "        drop_path_rate=0.,  \n",
    "        drop_block_rate=None,\n",
    "    )\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "resume_state = torch.load(trained_model_path)\n",
    "model.load_state_dict(resume_state['net'])\n",
    "\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scene_graph(preds, gts, save_name):\n",
    "    MAE = np.mean(np.abs(np.array(preds) - np.array(gts)))\n",
    "    \n",
    "#     save_path = os.path.join(save_dir, save_name)\n",
    "    xs = np.arange(len(gts))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(f'MAE: {MAE:.3f}')\n",
    "    plt.plot(xs, gts, color='green', label='GT')\n",
    "    plt.plot(xs, preds, color='blue', label='Predictions')\n",
    "    plt.legend()\n",
    "#     plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_scene(model, scene_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        gts = []\n",
    "        AEs = []  # Absolute Errors\n",
    "        SEs = []  # Squared Errors\n",
    "\n",
    "        for idx, (img, img_patches, gt_patches) in enumerate(scene_dataloader):\n",
    "            img_patches = img_patches.squeeze().cuda()\n",
    "            gt_patches = gt_patches.squeeze().unsqueeze(1)  # Remove batch dim, insert channel dim\n",
    "            img = img.squeeze()  # Remove batch dimension\n",
    "            _, img_h, img_w = img.shape  # Obtain image dimensions. Used to reconstruct GT and Prediction\n",
    "            \n",
    "#             img = restore_transform(img)\n",
    "\n",
    "            pred_den = model.forward(img_patches)  # Precicted density crops\n",
    "            pred_den = pred_den.cpu()\n",
    "\n",
    "            # Restore GT and Prediction\n",
    "            gt = img_equal_unsplit(gt_patches, cfg_data.OVERLAP, cfg_data.IGNORE_BUFFER, img_h, img_w, 1)\n",
    "            den = img_equal_unsplit(pred_den, cfg_data.OVERLAP, cfg_data.IGNORE_BUFFER, img_h, img_w, 1)\n",
    "            gt = gt.squeeze()  # Remove channel dim\n",
    "            den = den.squeeze()  # Remove channel dim\n",
    "            \n",
    "            \n",
    "            pred_cnt = den.sum() / label_factor\n",
    "            gt_cnt = gt.sum() / cfg_data.LABEL_FACTOR\n",
    "            \n",
    "            preds.append(pred_cnt)\n",
    "            gts.append(gt_cnt)\n",
    "            AEs.append(torch.abs(pred_cnt - gt_cnt).item())\n",
    "            SEs.append(torch.square(pred_cnt - gt_cnt).item())\n",
    "            relative_error = AEs[-1] / gt_cnt * 100\n",
    "            \n",
    "        MAE = np.mean(AEs)\n",
    "        MSE = np.sqrt(np.mean(SEs))\n",
    "\n",
    "    return preds, gts, MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAEs = []\n",
    "MSEs = []\n",
    "for idx, scene_dataloader in enumerate(my_dataloaders):\n",
    "    print(f'Scene {idx + 1}')\n",
    "\n",
    "    preds, gts, MAE, MSE = eval_on_scene(model, scene_dataloader)\n",
    "    print(f'    MAE/MSE: {MAE:.3f}/{MSE:.3f}')\n",
    "    MAEs.append(MAE)\n",
    "    MSEs.append(MSE)\n",
    "\n",
    "    save_scene_graph(preds, gts, f'scene_{idx + 1}.jpg')\n",
    "    \n",
    "overal_MAE = np.mean(MAEs)\n",
    "overal_MSE = np.mean(MSEs)\n",
    "print(f'avg MAE/MSE: {overal_MAE:.3f}/{overal_MSE:.3f}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThesisMain",
   "language": "python",
   "name": "thesismain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
